{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "widths = [1]*32\n",
    "df = pd.read_fwf('digitdata/optdigits-orig_train.txt', widths=widths, header=None, skiprows=lambda x : (x+1) % 33 == 0)\n",
    "# df\n",
    "df_Y = pd.read_fwf('digitdata/optdigits-orig_train.txt', widths=[2], header=None, skiprows=lambda x : (x+1) % 33 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trainX = pd.DataFrame(df.values.reshape(2436, -1))\n",
    "df_trainY = df_Y\n",
    "df_trainY.columns = ['label']\n",
    "# df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_fwf('digitdata/optdigits-orig_test.txt', widths=widths, header=None, skiprows=lambda x : (x+1) % 33 == 0)\n",
    "df_Y = pd.read_fwf('digitdata/optdigits-orig_test.txt', widths=[2], header=None, skiprows=lambda x : (x+1) % 33 != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_testX = pd.DataFrame(df.values.reshape(444, -1))\n",
    "df_testY = df_Y\n",
    "df_testY.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(feature_set, w):\n",
    "    predicted = np.empty(len(feature_set))\n",
    "    for idx in range(len(feature_set)):\n",
    "        arg_max, predicted_class = 0, 0\n",
    "        feature_vector = feature_set.iloc[idx]\n",
    "\n",
    "        for c in range(10):\n",
    "            current = np.dot(feature_vector, w[c])\n",
    "            if current >= arg_max:\n",
    "                arg_max, predicted_class = current, c\n",
    "                \n",
    "        predicted[idx] = predicted_class\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_acc_conf_mat(actual, prediction):\n",
    "    y_pred = pd.Series(prediction)\n",
    "    df_confusion = pd.crosstab(actual, y_pred)\n",
    "\n",
    "    conf_percent = df_confusion.values / df_confusion.sum(axis=1).values.reshape(-1,1)\n",
    "    df_conf_percent = round(pd.DataFrame(conf_percent).rename_axis('Actual').rename_axis('Prediction', axis=1), 4)*100\n",
    "\n",
    "    return np.mean(np.diag(df_conf_percent)), df_conf_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_trainX.shape\n",
    "df_train = pd.concat([df_trainX, df_trainY], axis=1)\n",
    "epoch_num = 3\n",
    "enumerate(df_train_all)\n",
    "df_num = 0\n",
    "df_train.values\n",
    "# df_train N x 1024, N = 2436\n",
    "# weight_vectors_zero_rand \n",
    "np.array(df_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       1\n",
       "12       1\n",
       "13       1\n",
       "14       1\n",
       "15       1\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "995      0\n",
       "996      0\n",
       "997      0\n",
       "998      0\n",
       "999      0\n",
       "1000     0\n",
       "1001     0\n",
       "1002     0\n",
       "1003     1\n",
       "1004     1\n",
       "1005     1\n",
       "1006     1\n",
       "1007     1\n",
       "1008     1\n",
       "1009     1\n",
       "1010     1\n",
       "1011     0\n",
       "1012     0\n",
       "1013     0\n",
       "1014     0\n",
       "1015     0\n",
       "1016     0\n",
       "1017     0\n",
       "1018     0\n",
       "1019     0\n",
       "1020     0\n",
       "1021     0\n",
       "1022     0\n",
       "1023     0\n",
       "label    0\n",
       "Name: 1, Length: 1025, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_all = [pd.concat([df_trainX, df_trainY], axis=1),         # no bias, fixed order\n",
    "                pd.concat([df_trainX, df_trainY], axis=1),         # with bias, fixed order\n",
    "                pd.concat([df_trainX, df_trainY], axis=1),         # no bias, random order\n",
    "                pd.concat([df_trainX, df_trainY], axis=1)]         # with bias, random order\n",
    "df_train_all[1].insert(1024, 'bias', 1)\n",
    "\n",
    "df_train_all[2] = df_train_all[2].reindex(np.random.permutation(df_train_all[1].index))\n",
    "df_train_all[2] = df_train_all[2].reset_index(drop=True)\n",
    "\n",
    "df_train_all[3].insert(1024, 'bias', 1)\n",
    "df_train_all[3] = df_train_all[3].reindex(np.random.permutation(df_train_all[3].index))\n",
    "df_train_all[3] = df_train_all[3].reset_index(drop=True)\n",
    "\n",
    "df_test_all = [pd.concat([df_testX, df_testY], axis=1),         # no bias\n",
    "               pd.concat([df_testX, df_testY], axis=1)]         # with bias\n",
    "df_test_all[1].insert(1024, 'bias', 1)\n",
    "\n",
    "epoch_nums = [3, 5, 10]\n",
    "# for epoch_num in epoch_nums:\n",
    "epoch_num = epoch_nums[0]      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train\n",
    "\n",
    "for df_num, df_train in enumerate(df_train_all):\n",
    "        weight_vectors_zero_rand = [np.zeros((10, 1024)), \n",
    "                                    np.zeros((10, 1025)), \n",
    "                                    np.random.rand(10, 1024)*10, \n",
    "                                    np.random.rand(10, 1025)*10]\n",
    "        for weight_num, weight_vectors in enumerate(weight_vectors_zero_rand):\n",
    "            if df_train.values.shape[1] != weight_vectors.shape[1] + 1:  \n",
    "                continue\n",
    "            acc_per_epoch = []\n",
    "            eta = 1\n",
    "            for epoch in range(1,epoch_num+1):\n",
    "                for idx in range(len(df_train)):\n",
    "                    arg_max, predicted_class = 0, 0\n",
    "                    category = df_train.iloc[idx,-1]\n",
    "                    feature_vector = df_train.iloc[idx,:-1].values\n",
    "                    \n",
    "                    \n",
    "                    for c in range(10):\n",
    "                        current = np.dot(feature_vector, weight_vectors[c])\n",
    "                        if current >= arg_max:\n",
    "                            arg_max, predicted_class = current, c\n",
    "\n",
    "                    # update weights \n",
    "                    if not (category == predicted_class):\n",
    "                        weight_vectors[category] += eta * feature_vector\n",
    "                        weight_vectors[predicted_class] -= eta * feature_vector\n",
    "                train_pred = predict(df_train.iloc[:,:-1], weight_vectors)\n",
    "                acc, _ = calculate_acc_conf_mat(df_train.iloc[:,-1], train_pred)\n",
    "                acc_per_epoch.append(acc)\n",
    "                eta = eta / epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # data visulization\n",
    "\n",
    "# f, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "#             ax.plot(range(1,epoch_num+1), acc_per_epoch, marker='.')\n",
    "#             ax.set_xlabel('Epoch', fontsize=18)\n",
    "#             ax.set_ylabel('Accuracy', fontsize=18)\n",
    "#             title_str = ''\n",
    "#             if weight_num > 1:\n",
    "#                 title_str += 'Weights initialized to Random'\n",
    "#                 if weight_vectors.shape[1] == 1025:\n",
    "#                     title_str += ', with Bias'\n",
    "#                     if df_num > 1:\n",
    "#                         title_str += ', Random Ordering of training set'\n",
    "#                     else:\n",
    "#                         title_str += ', Fixed Ordering of training set'\n",
    "#                 else:\n",
    "#                     title_str += ', no Bias'\n",
    "#                     if df_num > 1:\n",
    "#                         title_str += ', Random Ordering of training set'\n",
    "#                     else:\n",
    "#                         title_str += ', Fixed Ordering of training set'\n",
    "#             else:\n",
    "#                 title_str += 'Weights initialized to Zeros'\n",
    "#                 if weight_vectors.shape[1] == 1025:\n",
    "#                     title_str += ', with Bias'\n",
    "#                     if df_num > 1:\n",
    "#                         title_str += ', Random Ordering of training set'\n",
    "#                     else:\n",
    "#                         title_str += ', Fixed Ordering of training set'\n",
    "#                 else:\n",
    "#                     title_str += ', no Bias'\n",
    "#                     if df_num > 1:\n",
    "#                         title_str += ', Random Ordering of training set'\n",
    "#                     else:\n",
    "#                         title_str += ', Fixed Ordering of training set'\n",
    "#             plt.title('Training Accuracy vs. Epoch Plot ({})'.format(title_str), fontsize=20)\n",
    "#             plt.show()\n",
    "\n",
    "#             if weight_vectors.shape[1] == 1025:\n",
    "#                 df_to_test = df_test_all[1]\n",
    "#             else:\n",
    "#                 df_to_test = df_test_all[0]\n",
    "#             test_pred = predict(df_to_test.iloc[:,:-1], weight_vectors)\n",
    "#             acc_test, conf_mat_test = calculate_acc_conf_mat(df_to_test.iloc[:,-1], test_pred)\n",
    "#             print('Test set Confusion Matrix: Actual vs. Prediction')\n",
    "#             display(conf_mat_test)\n",
    "#             display(pd.DataFrame(np.diag(conf_mat_test), columns=['Accuracy']))\n",
    "#             print('Average Accuracy: {}'.format(acc_test))\n",
    "#             print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
